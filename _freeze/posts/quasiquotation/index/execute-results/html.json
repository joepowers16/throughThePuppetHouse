{
  "hash": "ae9dd73f703d1086867f89f88153ba67",
  "result": {
    "markdown": "---\ntitle: \"Write clearer custom functions in R using quasiquotation\"\nauthor: \"Joseph Powers\"\ndate: '2018-11-17'\ncategories: [functions, nonstandard evaluation]\nimage: \"air_quotes.png\"\ndraft: false\nwarning: false\nmessage: false\n---\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](https://media.giphy.com/media/qs6ev2pm8g9dS/giphy.gif){fig-align='center'}\n:::\n:::\n\n\n# TLDR\nThe functions in `dplyr`, `tidyr`, and `ggplot2` handle their arguments differently than most R functions, and this can complicate writing your own custom functions. However, if you know when to use quasiquotation functions like `enquo()` & `!!`, you can quickly write very powerful custom functions that take full advantage of `dplyr`, `tidyr`, and `ggplot2`. This post demonstrates standard use cases for writing custom functions that leverage `enquo()` & `!!`, `enquos()` & `!!!`, `quo_name()` and the helper function `:=`, which is godsend for naming new variables inside of custom functions. \n\n# Why use quasiquotation?\nI'll assume that readers of this post rely on `dplyr` & `tidyr` for data manipulation, but have experienced some frustration when trying to turn their best data manipulation scripts into custom functions that rely on `dplyr` and `tidyr` verbs. Quasiquotation can relieve that pain.\n\nI'll start by making a small dataframe `ds_mt` for demonstration purposes.\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\nds_mt <- mtcars %>% select(cyl) %>% slice(1:5)\n```\n:::\n\n\n## A custom function with no `dplyr` verbs\nNow I'll write a very simple function, `double()`, that uses no `dplyr` verbs.\n\n::: {.cell}\n\n```{.r .cell-code}\ndouble <- function(x){\n  x * 2\n}\n```\n:::\n\n\nIn the function above, `x` is referred to as a `formal argument`. Formal arguments like `x` map to `calling argument(s)` supplied by the user such as `3` & `ds_mt$cyl` in the chunk below. This distinction will be important to avoid confusion later on. \n\n\n::: {.cell}\n\n```{.r .cell-code}\ndouble(3) # same as double(x = 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 6\n```\n:::\n\n```{.r .cell-code}\ndouble(x = ds_mt$cyl) # same as double(ds_mt$cyl)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 12 12  8 12 16\n```\n:::\n:::\n\n\nOur function `double()` can be used within a `dplyr` function like `mutate()` ... \n\n::: {.cell}\n\n```{.r .cell-code}\nds_mt %>% mutate(cyl_2 = double(cyl))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                  cyl cyl_2\nMazda RX4           6    12\nMazda RX4 Wag       6    12\nDatsun 710          4     8\nHornet 4 Drive      6    12\nHornet Sportabout   8    16\n```\n:::\n:::\n\n\n... but if we write a new version of `double()` called `double_dplyr` that has `dplyr` verbs inside, then mapping to our arguments gets more complicated. \n\n## A custom function utilizing `dplyr` verbs\nNotice how the function below, `double_dplyr()`, fails to find `cyl` within our data `ds_mt`:\n\n::: {.cell}\n\n```{.r .cell-code}\ndouble_dplyr <- function(data, x){\n  data %>% \n    mutate(new_var = x * 2)\n}\n\nds_mt %>% double_dplyr(x = cyl)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in `mutate()`:\nℹ In argument: `new_var = x * 2`.\nCaused by error:\n! object 'cyl' not found\n```\n:::\n:::\n\n\nIn order for our new function, `double_dplyr()`, to successfully map its arguments, we need to utilize quasiquotation inside the guts of the function. \n\n**Note**: I am not going to get into the weeds of [quasiquotation](https://adv-r.hadley.nz/quasiquotation.html), [tidyeval](https://www.rstudio.com/resources/webinars/tidy-eval/), and [nonstandard evaluation](https://cran.r-project.org/web/packages/dplyr/vignettes/programming.html) in this post. The internet has covered these topics in great detail already. This post is a demonstration of everyday use cases for using quasiquotation to write clear and reliable functions. \n\n# Writing custom functions with quasiquotation\nI have read up on quasiquotation in detail, and for brief moments felt like I understood it. But when I am writing functions that utilize quasiquotation I prefer to think of this fairy tale:\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](https://media.giphy.com/media/tpTOw6sljB2U/giphy.gif){fig-align='center'}\n:::\n:::\n\n\nThe calling arguments users supply to your function are like genies: Magic, but dangerous to have floating around loose inside the function. `enquo()` traps the genie in the bottle for safe transport, and `!!` rubs the bottle to let him out and grant your wishes. \n\n::: {.cell}\n\n```{.r .cell-code}\ndouble_dplyr <- function(data, x){\n  x <- enquo(x)\n  data %>% \n    mutate(new_var = !!x * 2)\n}\n\nds_mt %>% double_dplyr(x = cyl)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                  cyl new_var\nMazda RX4           6      12\nMazda RX4 Wag       6      12\nDatsun 710          4       8\nHornet 4 Drive      6      12\nHornet Sportabout   8      16\n```\n:::\n:::\n\n\nThe above function now works fine, but the name of the new variable `new_var` is hard-wired into the guts of the function, and is not an informative name to have by default. \n\nA better written function would enable the user to name the new variable as they see fit...\n\n::: {.cell}\n\n```{.r .cell-code}\ndouble_dplyr <- function(data, x, new_var){\n  x <- enquo(x)\n  new_var <- enquo(new_var)\n  \n  data %>% \n    mutate(!!new_var = !!x * 2)\n}\n```\n\n::: {.cell-output .cell-output-error}\n```\nError: <text>:6:22: unexpected '='\n5:   data %>% \n6:     mutate(!!new_var =\n                        ^\n```\n:::\n:::\n\n\n... but now the above function does not work. The code breaks at the \"=\" sign. \n\nNaming `new_var` as a string will not help either. Because in this context `mutate()` is not going to look for the calling argument that `new_var` maps to. In this context `mutate()` will create a new variable named `new_var` rather than \"cyl_2\". \n\n::: {.cell}\n\n```{.r .cell-code}\ndouble_dplyr <- function(data, x, new_var){\n  x <- enquo(x)\n  new_var <- enquo(new_var)\n  \n  data %>% \n    mutate(new_var = !!x * 2)\n}\n\nds_mt %>% double_dplyr(x = cyl, new_var = \"cyl_2\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                  cyl new_var\nMazda RX4           6      12\nMazda RX4 Wag       6      12\nDatsun 710          4       8\nHornet 4 Drive      6      12\nHornet Sportabout   8      16\n```\n:::\n:::\n\n\nThe solution is to use `enquo()` and `!!` in combination with a helper function `:=` instead of `=` inside of `mutate()`. \n\n::: {.cell}\n\n```{.r .cell-code}\ndouble_dplyr <- function(data, x, new_var){\n  x <- enquo(x)\n  new_var <- enquo(new_var)\n  \n  data %>% \n    mutate(!!new_var := !!x * 2)\n}\n\nds_mt %>% double_dplyr(x = cyl, new_var = cyl_2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                  cyl cyl_2\nMazda RX4           6    12\nMazda RX4 Wag       6    12\nDatsun 710          4     8\nHornet 4 Drive      6    12\nHornet Sportabout   8    16\n```\n:::\n:::\n\n\nEven better we can write the function to automatically generate a name for the new variable by using `quo_name()` can convert expressions to strings.\n\n::: {.cell}\n\n```{.r .cell-code}\ndouble_dplyr <- function(data, x){\n  x <- enquo(x)\n  new_var <- paste0(quo_name(x), \"_2\")\n  \n  data %>% \n    mutate(!!new_var := !!x * 2)\n}\n\nds_mt %>% double_dplyr(x = cyl)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                  cyl cyl_2\nMazda RX4           6    12\nMazda RX4 Wag       6    12\nDatsun 710          4     8\nHornet 4 Drive      6    12\nHornet Sportabout   8    16\n```\n:::\n:::\n\n\n## Bonus Material: \nAnd just because it took me so long to figure out, I'll include an example that utilizes a formal argument (e.g., `groups`) that can handle multiple calling arguments, and `...`, which allows you to pass optional arguments like \"na.rm = TRUE\" to nested calls within your function. \n\n::: {.cell}\n\n```{.r .cell-code}\nmean_by_group <- function(data, x, groups, ...){\n  x <- enquo(x)\n  grp_mean <- paste0(quo_name(x), \"_mean\")\n  \n  groups <- enquos(groups)\n  \n  data %>% \n    group_by_at(vars(!!!groups)) %>% \n    summarise(\n      !!grp_mean := mean(!!x, ...)\n    )\n}\n\n# Example using groups with multiple arguments\nmtcars %>% mean_by_group(x = mpg, groups = c(am, cyl), na.rm = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 3\n# Groups:   am [2]\n     am   cyl mpg_mean\n  <dbl> <dbl>    <dbl>\n1     0     4     22.9\n2     0     6     19.1\n3     0     8     15.0\n4     1     4     28.1\n5     1     6     20.6\n6     1     8     15.4\n```\n:::\n\n```{.r .cell-code}\n# Example using groups with a single argument\nmtcars %>% mean_by_group(x = mpg, groups = cyl, na.rm = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 2\n    cyl mpg_mean\n  <dbl>    <dbl>\n1     4     26.7\n2     6     19.7\n3     8     15.1\n```\n:::\n:::\n\n\n# Conclusion: \nIf you know when to use `enquo()`and `!!` you can use dplyr verbs inside custom functions that are simple to call and easy to understand.    \n\n# Resources & Credits\n[Functions Chapter in Advanced R](http://adv-r.had.co.nz/Functions.html) for more information on argument vocabulary and mapping defaults. \n\nHat tip to @[akrun](https://stackoverflow.com/questions/53160709/pass-multiple-calling-arguments-to-a-formal-argument-in-dplyr-custom-function-wi/53160726#53160726) for informing me that `group_by_at()` can handle one or many grouping arguments inside a custom function. \n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}